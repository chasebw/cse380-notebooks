{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_1_About_Paths_in_Word_Graphs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCPa62crKG/CaSoIf4SVIa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.2 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byui-cse/cse380-notebooks/blob/master/11_1_About_Paths_in_Word_Graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdAeTh17kn01"
      },
      "source": [
        "# About Paths in Word Graphs\n",
        "## Divide Pair Conquer\n",
        "### Due: Monday, 15 March 2021, 11:59 pm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJHGM9eQkwxH"
      },
      "source": [
        "## Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM3LBOlNkzid"
      },
      "source": [
        "Word graphs are like those in Exercise 381, the nodes are words, the links are between words that differ by only one letter in the same position (e.g., **wind** and **wins** differ in the fourth letter only, so that defines a link. But **dine** and **tone** differ in the first and second letters, so no link there)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxO6SnVXoFWY"
      },
      "source": [
        "## TODO Find Short Paths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pASpYbc-oGns"
      },
      "source": [
        "**Without** looking online at any of the 5 billion web sites devoted to this problem, create a graph representation using the following \"universe\" of words:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPLq4YOJoLab"
      },
      "source": [
        "import json, urllib.request\n",
        "words = []\n",
        "# word list comes from here: https://github.com/dwyl/english-words\n",
        "url = \"https://raw.githubusercontent.com/dwyl/english-words/master/words_dictionary.json\"\n",
        "with urllib.request.urlopen(url) as f: \n",
        "  words = json.loads(f.read())\n",
        "  print('windy' in words)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dry', 'dey', 'wey', 'wet']\n",
            "['read', 'reqd', 'redd', 'rede', 'ride']\n"
          ]
        }
      ],
      "source": [
        "from functools import cache\n",
        "\n",
        "def one_letter_different(original_word, same_length_words):\n",
        "    count = 0\n",
        "\n",
        "    one_letter_different = []\n",
        "\n",
        "    for word in same_length_words:\n",
        "        count = 0\n",
        "        for letter1,letter2 in zip(word, original_word):\n",
        "            if (letter1 != letter2):\n",
        "                count+=1\n",
        "        if(count == 1):\n",
        "            one_letter_different.append(word)\n",
        "    return one_letter_different\n",
        "\n",
        "\n",
        "@cache\n",
        "def get_adjacent_words(word):\n",
        "    len_word = len(word)\n",
        "    same_length_words = [x for x in words if len_word == len(x)]\n",
        "    adjacent_words = one_letter_different(word,same_length_words)\n",
        "    return adjacent_words\n",
        "\n",
        "def grab_paths(starting_word, dest):\n",
        "    adj_words = get_adjacent_words(starting_word)\n",
        "    paths = []\n",
        "    paths.append([starting_word])\n",
        "\n",
        "    found = False\n",
        "    while(found):\n",
        "        # Go through each path we have so far\n",
        "        for path in paths:\n",
        "            # Grab the last item in the path\n",
        "            # Lets find adjacent words for it\n",
        "            new_adj_words = get_adjacent_words(path[-1])\n",
        "            # lets make a new path for each adjacent\n",
        "            for new_adjacent in new_adj_words:\n",
        "                paths.append(path + [new_adjacent])\n",
        "            # Remove it so we don't duplicate it\n",
        "            paths.remove(path)\n",
        "            if(dest in new_adj_words):\n",
        "                found = True\n",
        "                path.append(dest)\n",
        "                return path\n",
        "\n",
        "\n",
        "path = []\n",
        "print(grab_paths(\"dry\", \"wet\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['read', 'reqd', 'redd', 'rede', 'ride']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"read\", \"ride\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fish', 'fisc', 'fist', 'filt', 'fill', 'foll', 'fowl']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"fish\", \"fowl\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hate', 'have', 'hove', 'love']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"hate\", \"love\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hate', 'have', 'hove', 'love']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"hate\", \"love\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['head', 'dead', 'deed', 'feed', 'feet']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"head\", \"feet\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['poor', 'pook', 'rook', 'rock', 'rick', 'rich']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"poor\", \"rich\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sick', 'dick', 'wick', 'wilk', 'will', 'well']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"sick\", \"well\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['warm', 'yarm', 'yard', 'card', 'cord', 'cold']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"warm\", \"cold\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['work', 'fork', 'pork', 'perk', 'peak', 'plak', 'play']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"work\", \"play\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['black', 'clack', 'click', 'clink', 'cline', 'chine', 'whine', 'white']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"black\", \"white\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bread', 'break', 'breck', 'brack', 'brank', 'brant', 'brast', 'boast', 'toast']\n"
          ]
        }
      ],
      "source": [
        "print(grab_paths(\"bread\", \"toast\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THnbd22gocyt"
      },
      "source": [
        "Find by hand the shortest paths for as many of the following endpoints as you can. Or, if you have time, write code to find these paths:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sir5gH7cpQFB"
      },
      "source": [
        "### From \"dry\" to \"wet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXoZiV9xtnvO"
      },
      "source": [
        "dry\n",
        "day\n",
        "way\n",
        "wad\n",
        "wed\n",
        "wet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6V-ITRMpRvE"
      },
      "source": [
        "### From \"read\" to \"ride\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLOTZRAVpVKF"
      },
      "source": [
        "### From \"fish\" to \"fowl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm0_qn79pWaZ"
      },
      "source": [
        "### From \"hate\" to \"love\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwsoOSr2pXsI"
      },
      "source": [
        "### From \"head\" to \"feet\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYmmwLDApY-a"
      },
      "source": [
        "### From \"poor\" to \"rich\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvEyvK3ypaR5"
      },
      "source": [
        "### From \"sick\" to \"well\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KzWkpn3pb2H"
      },
      "source": [
        "### From \"warm\" to \"cold\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nriebmvRpg9m"
      },
      "source": [
        "### From \"work\" to \"play\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn1gMDAvpidg"
      },
      "source": [
        "### From \"bane\" to \"boon\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZ0UQQBGpjvy"
      },
      "source": [
        "### From \"black\" to \"white\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUhtca6YplBL"
      },
      "source": [
        "### From \"bread\" to \"toast\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drhFyUbnpmwQ"
      },
      "source": [
        "## TODO Go Above and Beyond"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y_YdUrapoaE"
      },
      "source": [
        "Think of ways to change the definition of a link in a word graph to make it possible (although perhaps costlier) to move from word to word."
      ]
    }
  ]
}